# DeepFake Text Detection

## Project Description

This project aims to detect deepfake texts generated by sophisticated natural language models. By leveraging adversarial training and fine-tuning on models such as BERT and RoBERTa, the project enhances the robustness of deepfake text detection systems against adversarial attacks.

## Workflow Overview

1. **Data Collection and Preparation**
   - **Datasets Used**:
     - A comprehensive dataset of 447,674 texts, including both human-written and machine-generated samples from sources like CNN/DailyMail, IMDb, and OpenAI.
     - To access our data, DFT perturbed data, and test data provided by the authors, as well as the model checkpoints for fully trained and DFT-trained BERT, ROBERTa, and CoLA models for GRUEN, and the counter-fitted vectors file for the DFT attack, please visit the following link: https://drive.google.com/drive/folders/1zbHR0m91j1DYzVMjpiF6ptqEXTQOB_Cy?usp=sharing

   - **Preprocessing Steps**:
     1. **Loading Data**: JSON Lines files are read, and data is converted into a list of dictionaries.
     2. **Label Modification**: Labels are standardized (e.g., 'machine' for 0, 'human' for 1).
     3. **Text Truncation**: Texts are truncated to a maximum of 512 tokens.
     4. **Splitting Data**: Data is split into training, testing, and validation sets (70-15-15 split).

2. **Adversarial Sample Generation**
   - **Tool Used**: DFTFooler
   - **Perturbation Techniques**:
     - Token substitution
     - Sentence restructuring
     - Paraphrasing
   - **Perturbation Variations**: 
     - 2 and 10 perturbations on both truncated and untruncated data

3. **Model Training and Fine-Tuning**
   - **Models Used**:
     - BERT-Defense
     - RoBERTa-Defense
     - GLTR-BERT
     - GLTR-GPT2
   - **Training Setup**:
     - Fine-tuning with varying sample sizes (30, 100, 14,000)
     - Hyperparameters: Learning rate, batch size, number of epochs
   - **Adversarial Training**: Incorporating adversarial samples to enhance model robustness

4. **Evaluation**
   - **Metrics Used**:
     - Precision, Recall, F1 Score
     - GRUEN Score
   - **Confusion Matrix**: Used to visualize performance

5. **Results and Analysis**
   - **Performance Comparison**: Evaluating model performance before and after adversarial training
   - **Robustness Testing**: Assessing model resistance to adversarial attacks in real-world scenarios

## File Descriptions

### data_preprocessing.py
Handles data loading, label modification, text truncation, and data splitting.

### dftfooler.py
Generates adversarial samples using DFTFooler with various perturbation techniques.

### train_model.py
Trains the models (BERT, RoBERTa, GLTR-BERT, GLTR-GPT2) with the prepared dataset.

### evaluate_model.py
Evaluates the trained models using metrics such as precision, recall, F1 score, and GRUEN score.

## Usage

### Prerequisites

- Python 3.x
- PyTorch
- TensorFlow
- Hugging Face Transformers
- NumPy
- Scikit-learn

### Steps

1. Clone the repository:
    ```bash
    git clone https://github.com/kalyan1998/DeepFakeTextDetection.git
    cd DeepFakeTextDetection
    ```

2. Install the required Python libraries:
    ```bash
    pip install -r requirements.txt
    ```

3. Run the preprocessing script:
    ```bash
    python data_preprocessing.py
    ```

4. Generate adversarial samples:
    ```bash
    python dftfooler.py
    ```

5. Train the model:
    ```bash
    python train_model.py
    ```

6. Evaluate the model:
    ```bash
    python evaluate_model.py
    ```

## Acknowledgments

- Clemson University
- Dr. Long Cheng, Clemson University

---

Feel free to explore the repository and use the provided tools and scripts. If you find this project useful, please give it a star!

